# Azure OpenAI Configuration for GPT Models (Chat/Completion)
# For shell sourcing (use with: source az.secret)
export AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
export AZURE_OPENAI_API_KEY=your-api-key-here
export AZURE_OPENAI_DEPLOYMENT=gpt-4
export AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Azure OpenAI Configuration for Embeddings
# Often embeddings are deployed on a different Azure OpenAI resource than GPT models.
# If these are not set, the embeddings module falls back to the main AZURE_OPENAI_* vars above.
export AZURE_OPENAI_EMBEDDING_ENDPOINT=https://your-embedding-resource.openai.azure.com/
export AZURE_OPENAI_EMBEDDING_API_KEY=your-embedding-api-key-here
export AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
export AZURE_OPENAI_EMBEDDING_API_VERSION=2024-02-15-preview

# MCP Server URL (default works in docker-compose)
export MCP_SERVER_URL=http://mcp-http:8000

# Web Client Port
export PORT=8080

# GitHub Integration (for creating CodeBundle request issues)
# Create a token at: https://github.com/settings/tokens
# Required scope: 'repo' (for creating issues)
export GITHUB_TOKEN=ghp_your_github_token_here

# Note: Docker Compose will automatically ignore the 'export' keyword
# This file can be sourced in shell: source az.secret
# Or used with docker-compose: env_file: az.secret

